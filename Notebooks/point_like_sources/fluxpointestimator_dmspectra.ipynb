{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations and set-up checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check package versions\n",
    "import gammapy\n",
    "import numpy as np\n",
    "import astropy\n",
    "import regions\n",
    "import math\n",
    "\n",
    "print(\"gammapy:\", gammapy.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"astropy\", astropy.__version__)\n",
    "print(\"regions\", regions.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import gca\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from regions import CircleSkyRegion\n",
    "\n",
    "from gammapy.datasets import SpectrumDatasetOnOff, SpectrumDataset, Datasets, FluxPointsDataset\n",
    "from gammapy.makers import SpectrumDatasetMaker\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    PowerLawSpectralModel,\n",
    "    SkyModel,\n",
    "    PointSpatialModel,\n",
    "    EBLAbsorptionNormSpectralModel\n",
    ")\n",
    "from gammapy.astro.darkmatter import DarkMatterAnnihilationSpectralModel\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.data import Observation\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.estimators import FluxPointsEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation parameters parameters\n",
    "livetime = 300 * u.h\n",
    "\n",
    "pointing = SkyCoord(150.57, -13.26, unit=\"deg\", frame=\"galactic\")\n",
    "offset = 1.0 * u.deg\n",
    "on_region_radius = Angle(\"1.0 deg\")\n",
    "on_region = CircleSkyRegion(center=pointing, radius=on_region_radius)\n",
    "\n",
    "# Energy axis in TeV\n",
    "emin = 30/1000\n",
    "emax = 100\n",
    "energy_axis = MapAxis.from_energy_bounds(emin, emax, 10, unit=\"TeV\", name=\"energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define spectral model \n",
    "JFAC = 3.03e18 * u.Unit(\"GeV2 cm-5\") # Perseus c-m moline17+ srd VL-II\n",
    "mDM = 10000*u.Unit(\"GeV\")\n",
    "channel = \"b\"\n",
    "redshift = 0.017284\n",
    "spectral_model = DarkMatterAnnihilationSpectralModel(\n",
    "    mass=mDM, \n",
    "    channel=channel, \n",
    "    jfactor=JFAC, \n",
    "    z=redshift\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EBL option, uncomment if want to use. In the following change spectral_model->model_simu\n",
    "#absorption = EBLAbsorptionNormSpectralModel.read_builtin(\"dominguez\", redshift=redshift)\n",
    "#model_simu = spectral_model * absorption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plt.figure()\n",
    "plt.plot()\n",
    "spectral_model.plot([(emin*1000)/mDM.value, (emax*1000)/mDM.value], energy_power=1)\n",
    "form = plt.FormatStrFormatter('$%g$')\n",
    "gca().xaxis.set_major_formatter(form)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the spatial model\n",
    "spatial_model = PointSpatialModel(lon_0=l*u.Unit(\"deg\"), lat_0=b*u.Unit(\"deg\"), frame=\"galactic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sky model used in the dataset\n",
    "model = SkyModel(spectral_model=spectral_model, spatial_model=spatial_model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IRFs\n",
    "irfs = load_cta_irfs(\n",
    "    \"$GAMMAPY_DATA/prod3b-v2/bcf/North_z20_50h/irf_file.fits\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the observation\n",
    "obs = Observation.create(pointing=pointing, livetime=livetime, irfs=irfs)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the SpectrumDataset\n",
    "# NOTE: Even we don't set different energy ranges for recovered and true, if edisp is not considered then the \n",
    "# FluxPointEstimator breaks\n",
    "dataset_empty = SpectrumDataset.create(e_reco=energy_axis, region=on_region, name=\"obs-0\")\n",
    "maker = SpectrumDatasetMaker(selection=[\"exposure\", \"edisp\", \"background\"])\n",
    "\n",
    "dataset = maker.run(dataset_empty, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model on the dataset, and fake the counts on the first one to create the rest from here\n",
    "dataset.models = model\n",
    "dataset.fake(random_state=42)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the On/Off simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set off regions\n",
    "dataset_on_off = SpectrumDatasetOnOff.from_spectrum_dataset(dataset=dataset, acceptance=1, acceptance_off=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set the number of observations we want to create\n",
    "n_obs = 3\n",
    "\n",
    "# Create realizations\n",
    "datasets = Datasets()\n",
    "\n",
    "for idx in range(n_obs):\n",
    "    dataset_on_off.fake(\n",
    "        random_state=idx, npred_background=dataset.npred_background()\n",
    "    )\n",
    "    dataset_fake = dataset_on_off.copy(name=f\"obs-{idx}\")\n",
    "    dataset_fake.meta_table[\"OBS_ID\"] = [idx]\n",
    "    datasets.append(dataset_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the observations created\n",
    "table = datasets.info_table()\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check counts in one realization\n",
    "fig_2 = plt.figure(1)\n",
    "datasets[0].npred().plot_hist(label='Predicted S+B')\n",
    "datasets[0].npred_signal().plot_hist(label='Predicted S')\n",
    "datasets[0].npred_background().plot_hist(label='Predicted B')\n",
    "plt.legend()\n",
    "form = plt.FormatStrFormatter('$%g$')\n",
    "gca().xaxis.set_major_formatter(form)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check consistency in the sample of observaitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_counts = table[\"counts\"].mean()\n",
    "mean_error = table[\"counts\"].std()\n",
    "mean_counts_off = table[\"counts_off\"].mean()\n",
    "mean_off_error = table[\"counts_off\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].hist(table[\"counts\"], label=f\"{mean_counts} +- {mean_error}\")\n",
    "axes[0].set_xlabel(\"Counts\")\n",
    "axes[0].axvline(x=table[\"counts\"].mean(), color=\"red\")\n",
    "axes[0].axvspan(table[\"counts\"].mean()-table[\"counts\"].std(), table[\"counts\"].mean()+table[\"counts\"].std(), facecolor='r', alpha=0.2)\n",
    "axes[0].legend()\n",
    "axes[1].hist(table[\"counts_off\"], label=f\"{mean_counts_off} +- {mean_off_error}\")\n",
    "axes[1].set_xlabel(\"Counts Off\")\n",
    "axes[1].axvline(x=table[\"counts_off\"].mean(), color=\"red\")\n",
    "axes[1].axvspan(table[\"counts_off\"].mean()-table[\"counts_off\"].std(), table[\"counts_off\"].mean()+table[\"counts_off\"].std(), facecolor='r', alpha=0.2)\n",
    "axes[1].legend()\n",
    "\n",
    "form = plt.FormatStrFormatter('$%g$')\n",
    "gca().xaxis.set_major_formatter(form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux point estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set list of channels and masses we want to fit\n",
    "channels = [\"b\", \"tau\", \"W\"]\n",
    "masses = [100, 250, 500, 1000, 2500, 5000, 10000, 50000, 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = dict(mean={}, runs={})\n",
    "\n",
    "for ch in channels:\n",
    "    results[\"runs\"][ch] = {}\n",
    "    results[\"mean\"][ch] = {}\n",
    "    \n",
    "    for m in masses:\n",
    "            \n",
    "        # Fix to which DM model we want to fit the data\n",
    "        flux_model_fit = DarkMatterAnnihilationSpectralModel(\n",
    "            mass=m*u.Unit(\"GeV\"), \n",
    "            channel=ch, \n",
    "            jfactor=JFAC,\n",
    "            z=redshift\n",
    "        )\n",
    "        # Same here for the EBL\n",
    "        #flux_fit = flux_model_fit * absorption\n",
    "        model_fit = SkyModel(spectral_model=flux_model_fit, name=\"model-fit\")\n",
    "            \n",
    "        # Set the energy bins to use in the flux point estimator\n",
    "        # IMPORTANT: Don't try to fit further than the m, since the spectra drops abruptly   \n",
    "        energy_edges = np.array([emin, m/1000]) * u.TeV\n",
    "            \n",
    "        # Instantiate the estimator, here you can specify the range of values to search for norm\n",
    "        fpe = FluxPointsEstimator(energy_edges=energy_edges, norm_min=1e-6, norm_max=1e3, norm_n_values=50)\n",
    "           \n",
    "        upper_container = []\n",
    "        results[\"runs\"][ch][m] = {}\n",
    "        results[\"mean\"][ch][m] = {}\n",
    "        \n",
    "        for i in range(n_obs):\n",
    "            # Run the estimator\n",
    "            datasets[i].models = model_fit\n",
    "            flux_points = fpe.run(datasets=datasets[i])\n",
    "            \n",
    "            # Clean the possible NaNs in the ULs\n",
    "            for j in range(len(flux_points.table['norm_ul'])):\n",
    "                x = math.isnan(flux_points.table['norm_ul'][j])\n",
    "                if x == True:\n",
    "                    flux_points.table['norm_ul'][j] = 0\n",
    "                \n",
    "            # Save the data\n",
    "            upper_container.append(np.sum(flux_points.table['norm_ul']))\n",
    "            results[\"runs\"][ch][m][i] = flux_points.table_formatted\n",
    "    \n",
    "        results[\"mean\"][ch][m][0] = np.mean(upper_container)*3e-26\n",
    "        results[\"mean\"][ch][m][1] = np.std(upper_container)*3e-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gammapy has some troubles writing directly the table of the runs\n",
    "# if you want to save the data as txt file uncomment the next few lines of code\n",
    "# these results tables contain information about the likelihood and the fit, but not the complete likelihood profile\n",
    "#\n",
    "#res = np.zeros([n_obs, 23])\n",
    "#\n",
    "#for ch in channels:\n",
    "#    for m in masses:\n",
    "#        for i in range(n_obs):\n",
    "#            for j in range(23):\n",
    "#                if j==16:\n",
    "#                    res[i, j] = -90\n",
    "#                elif j==17:\n",
    "#                    res[i, j] = results[\"runs\"][ch][m][i][0][j][0]\n",
    "#                else:\n",
    "#                    res[i, j] = results[\"runs\"][ch][m][i][0][j]\n",
    "#        np.savetxt('results_{}_{}.txt'.format(ch, m), res, header='Columns corresponding to flux_points.table_formated in gammapy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange the data from the fits and save so we can plot it easily later\n",
    "\n",
    "sigmav = dict(ul={}, one_sigma={})\n",
    "for ch in channels:\n",
    "    sigmav[\"ul\"][ch] = []\n",
    "    sigmav[\"one_sigma\"][ch] = []\n",
    "    for m in masses:\n",
    "        sigmav[\"ul\"][ch].append(results[\"mean\"][ch][m][0])\n",
    "        sigmav[\"one_sigma\"][ch].append(results[\"mean\"][ch][m][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in channels:\n",
    "    sigmav[\"ul\"][ch] = np.asarray(sigmav[\"ul\"][ch])\n",
    "    np.savetxt('/mean_sigmav_{}.txt'.format(ch), sigmav[\"ul\"][ch])\n",
    "    sigmav[\"one_sigma\"][ch] = np.asarray(sigmav[\"one_sigma\"][ch])\n",
    "    np.savetxt('1sigma_sigmav_{}.txt'.format(ch), sigmav[\"one_sigma\"][ch])\n",
    "\n",
    "masses = np.asarray(masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the constraints\n",
    "\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "fig_4 = plt.figure(figsize=(9,7))\n",
    "\n",
    "for ch in channels:\n",
    "    plt.plot(masses*1e-3, sigmav[\"ul\"][ch], label='{}'.format(ch))\n",
    "    plt.fill_between(masses*1e-3, sigmav[\"ul\"][ch] - sigmav[\"one_sigma\"][ch], sigmav[\"ul\"][ch] + sigmav[\"one_sigma\"][ch], alpha=0.2)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Mass [TeV]', fontsize=15)\n",
    "plt.ylabel(r'$<\\sigma v$> [cm$^3$s$^{-1}$]', fontsize=15)\n",
    "plt.xlim(1e-1, 100)\n",
    "plt.legend()\n",
    "\n",
    "# Thermal relic cross-section\n",
    "plt.hlines(3e-26, 0.1, 100, ls=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1.savefig('original_spectra.png', quality=95, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_2.savefig('obs_counts.png', quality=95, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3.savefig('distr_counts.png', quality=95, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_4.savefig('sigmav_vs_mass.png', quality=95, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
