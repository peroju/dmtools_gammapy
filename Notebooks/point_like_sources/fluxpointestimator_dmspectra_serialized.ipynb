{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations and set-up checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check package versions\n",
    "import gammapy\n",
    "import numpy as np\n",
    "import astropy\n",
    "import regions\n",
    "import math\n",
    "\n",
    "print(\"gammapy:\", gammapy.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"astropy\", astropy.__version__)\n",
    "print(\"regions\", regions.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import gca\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from regions import CircleSkyRegion\n",
    "\n",
    "from gammapy.datasets import SpectrumDatasetOnOff, SpectrumDataset, Datasets, FluxPointsDataset\n",
    "from gammapy.makers import SpectrumDatasetMaker\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    PowerLawSpectralModel,\n",
    "    SkyModel,\n",
    "    PointSpatialModel,\n",
    "    EBLAbsorptionNormSpectralModel\n",
    ")\n",
    "from gammapy.astro.darkmatter import DarkMatterAnnihilationSpectralModel\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.data import Observation\n",
    "from gammapy.maps import MapAxis\n",
    "from gammapy.estimators import FluxPointsEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation parameters parameters\n",
    "livetime = 300 * u.h\n",
    "\n",
    "pointing = SkyCoord(150.57, -13.26, unit=\"deg\", frame=\"galactic\")\n",
    "offset = 1.5 * u.deg\n",
    "\n",
    "on_region_radius = Angle(\"0.5 deg\")\n",
    "\n",
    "#center = pointing.directional_offset_by(\n",
    "#    position_angle=0 * u.deg, separation=offset\n",
    "#)\n",
    "\n",
    "on_region = CircleSkyRegion(center=pointing, radius=on_region_radius)\n",
    "\n",
    "# Energy axis in TeV\n",
    "emin = 50/1000\n",
    "emax = 50\n",
    "\n",
    "energy_axis = MapAxis.from_energy_bounds(\n",
    "    emin, emax, 10, unit=\"TeV\", name=\"energy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define spectral model \n",
    "JFAC = 3.03e18 * u.Unit(\"GeV2 cm-5\") # Perseus c-m moline17+ srd VL-II\n",
    "mDM = 50000*u.Unit(\"GeV\")\n",
    "channel = \"tau\"\n",
    "redshift = 0.017284\n",
    "spectral_model = DarkMatterAnnihilationSpectralModel(\n",
    "    mass=mDM, \n",
    "    channel=channel, \n",
    "    jfactor=JFAC, \n",
    "    z=redshift\n",
    ")\n",
    "absorption = EBLAbsorptionNormSpectralModel.read_builtin(\"dominguez\", redshift=redshift)\n",
    "\n",
    "model_simu = spectral_model * absorption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plt.figure()\n",
    "plt.plot()\n",
    "model_simu.plot([(emin*1000)/mDM.value, (emax*1000)/mDM.value], energy_power=1)\n",
    "form = plt.FormatStrFormatter('$%g$')\n",
    "gca().xaxis.set_major_formatter(form)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sky model used in the dataset\n",
    "model = SkyModel(spectral_model=model_simu, name=\"perseus\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IRFs\n",
    "irfs = load_cta_irfs(\n",
    "    \"$GAMMAPY_DATA/prod3b-v2/bcf/North_z20_50h/irf_file.fits\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the observation\n",
    "obs = Observation.create(pointing=pointing, livetime=livetime, irfs=irfs)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the SpectrumDataset\n",
    "# NOTE: Even we don't set different energy ranges for recovered and true, if edisp is not considered then the \n",
    "# FluxPointEstimator breaks\n",
    "dataset_empty = SpectrumDataset.create(\n",
    "    e_reco=energy_axis, region=on_region, name=\"obs-0\"\n",
    ")\n",
    "maker = SpectrumDatasetMaker(selection=[\"exposure\", \"edisp\", \"background\"])\n",
    "\n",
    "dataset = maker.run(dataset_empty, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model on the dataset, and fake the first one to create the rest from here\n",
    "dataset.models = model\n",
    "dataset.fake(random_state=42)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the On/Off simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set off regions\n",
    "dataset_on_off = SpectrumDatasetOnOff.from_spectrum_dataset(\n",
    "    dataset=dataset, acceptance=1, acceptance_off=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create realizations\n",
    "\n",
    "n_obs = 100\n",
    "datasets = Datasets()\n",
    "\n",
    "for idx in range(n_obs):\n",
    "    dataset_on_off.fake(\n",
    "        random_state=idx, npred_background=dataset.npred_background()\n",
    "    )\n",
    "    dataset_fake = dataset_on_off.copy(name=f\"obs-{idx}\")\n",
    "    dataset_fake.meta_table[\"OBS_ID\"] = [idx]\n",
    "    datasets.append(dataset_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = datasets.info_table()\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check counts in one realization\n",
    "fig_2 = plt.figure(1)\n",
    "datasets[0].npred().plot_hist(label='Predicted S+B')\n",
    "datasets[0].npred_signal().plot_hist(label='Predicted S')\n",
    "datasets[0].npred_background().plot_hist(label='Predicted B')\n",
    "plt.legend()\n",
    "form = plt.FormatStrFormatter('$%g$')\n",
    "gca().xaxis.set_major_formatter(form)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check consistency in the sample of observaitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_counts = table[\"counts\"].mean()\n",
    "mean_error = table[\"counts\"].std()\n",
    "mean_counts_off = table[\"counts_off\"].mean()\n",
    "mean_off_error = table[\"counts_off\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].hist(table[\"counts\"], label=f\"{mean_counts} +- {mean_error}\")\n",
    "axes[0].set_xlabel(\"Counts\")\n",
    "axes[0].axvline(x=table[\"counts\"].mean(), color=\"red\")\n",
    "axes[0].axvspan(table[\"counts\"].mean()-table[\"counts\"].std(), table[\"counts\"].mean()+table[\"counts\"].std(), facecolor='r', alpha=0.2)\n",
    "axes[0].legend()\n",
    "axes[1].hist(table[\"counts_off\"], label=f\"{mean_counts_off} +- {mean_off_error}\")\n",
    "axes[1].set_xlabel(\"Counts Off\")\n",
    "axes[1].axvline(x=table[\"counts_off\"].mean(), color=\"red\")\n",
    "axes[1].axvspan(table[\"counts_off\"].mean()-table[\"counts_off\"].std(), table[\"counts_off\"].mean()+table[\"counts_off\"].std(), facecolor='r', alpha=0.2)\n",
    "axes[1].legend()\n",
    "\n",
    "form = plt.FormatStrFormatter('$%g$')\n",
    "gca().xaxis.set_major_formatter(form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux point estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [\"b\", \"tau\", \"W\"]\n",
    "masses = [100, 500, 1000, 5000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = dict(mean={}, runs={})\n",
    "\n",
    "for ch in channels:\n",
    "    results[\"runs\"][ch] = {}\n",
    "    results[\"mean\"][ch] = {}\n",
    "    \n",
    "    for m in masses:\n",
    "            \n",
    "        # Fix to which DM model we want to fit the data\n",
    "        flux_model_fit = DarkMatterAnnihilationSpectralModel(\n",
    "            mass=m*u.Unit(\"GeV\"), \n",
    "            channel=ch, \n",
    "            jfactor=JFAC,\n",
    "            z=redshift\n",
    "        )\n",
    "        flux_fit = flux_model_fit * absorption\n",
    "        model_fit = SkyModel(spectral_model=flux_fit, name=\"model-fit\")\n",
    "            \n",
    "        # Set the energy bins to use in the flux point estimator\n",
    "        energy_edges = np.array([emin, emax]) * u.TeV\n",
    "            \n",
    "        # Instantiate the estimator\n",
    "        fpe = FluxPointsEstimator(energy_edges=energy_edges)\n",
    "           \n",
    "        upper_container = []\n",
    "        results[\"runs\"][ch][m] = {}\n",
    "        results[\"mean\"][ch][m] = {}\n",
    "        \n",
    "        for i in range(n_obs):\n",
    "            # Run the estimator\n",
    "            datasets[i].models = model_fit\n",
    "            flux_points = fpe.run(datasets=datasets[i])\n",
    "            \n",
    "            # Clean the possible NaNs in the ULs\n",
    "            for j in range(len(flux_points.table['norm_ul'])):\n",
    "                x = math.isnan(flux_points.table['norm_ul'][j])\n",
    "                if x == True:\n",
    "                    flux_points.table['norm_ul'][j] = 0\n",
    "                \n",
    "            # Save the data\n",
    "            upper_container.append(np.sum(flux_points.table['norm_ul']))\n",
    "            results[\"runs\"][ch][m][i] = flux_points.table_formatted\n",
    "    \n",
    "        results[\"mean\"][ch][m][0] = np.mean(upper_container)*3e-26\n",
    "        results[\"mean\"][ch][m][1] = np.std(upper_container)*3e-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmav = dict(ul={}, one_sigma={})\n",
    "for ch in channels:\n",
    "    sigmav[\"ul\"][ch] = []\n",
    "    sigmav[\"one_sigma\"][ch] = []\n",
    "    for m in masses:\n",
    "        sigmav[\"ul\"][ch].append(results[\"mean\"][ch][m][0])\n",
    "        sigmav[\"one_sigma\"][ch].append(results[\"mean\"][ch][m][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in channels:\n",
    "    sigmav[\"ul\"][ch] = np.asarray(sigmav[\"ul\"][ch])\n",
    "    sigmav[\"one_sigma\"][ch] = np.asarray(sigmav[\"one_sigma\"][ch])\n",
    "masses = np.asarray(masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_4 = plt.figure(figsize=(9,7))\n",
    "\n",
    "for ch in channels:\n",
    "    plt.plot(masses*1e-3, sigmav[\"ul\"][ch], label='{}'.format(ch))\n",
    "    plt.fill_between(masses*1e-3, sigmav[\"ul\"][ch] - sigmav[\"one_sigma\"][ch], sigmav[\"ul\"][ch] + sigmav[\"one_sigma\"][ch], alpha=0.2)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('mass [TeV]')\n",
    "plt.ylabel(r'$<\\sigma v$> [cm$^3$s$^{-1}$]')\n",
    "plt.legend()\n",
    "plt.title(r'$m_{DM}$= 50 TeV, $\\tau^+\\tau^-$, N$_{runs}$ = 50')\n",
    "\n",
    "plt.hlines(3e-26, 0.1, 10, ls=\"--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1.savefig('original_spectra.png', quality=95, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_2.savefig('obs_counts.png', quality=95, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3.savefig('distr_counts.png', quality=95, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_4.savefig('sigmav_vs_mass_one_bin_10.png', quality=95, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
